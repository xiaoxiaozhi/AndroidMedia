#### RGB与YUV格式对比(H264视频编码01 02)

1. [RGB介绍](https://zhuanlan.zhihu.com/p/350656532)

> 光的三原色(RGB)和色彩的三原色(青色、黄色、洋红)。
> 色彩三原色用于绘画和印刷，运用在白色背景（如白纸）上的。在调颜料时，只需要用青色、洋红、黄色三种颜色就能够调出任何颜色，当将三种颜色的颜料等量混合时，就能得到黑色的颜料
> 光的三原色用于黑色背景(例如屏幕)，我们人眼所看到的任何颜色，都是由这三种颜色的光混合而成的。而白光则是这三种光等量混合在一起产生的。
> RGB占用内存 由于一个字节显示一种颜色所以3字节表示一个像素 ` W*H*3`

2. [YUV格式介绍](https://blog.csdn.net/liufish992/article/details/122234961)

> YUV类似RGB，都能代表颜色，表示颜色。标准定义电视中，Y计算公式为：`Y' = 0.299R + 0.587G + 0.114B`现代电视技术使用了更新的公式，用于高清电视` Y' = 0.2125R + 0.7154G + 0.0721B`
> 公式相关定义可查询ITU-R BT.601
> U和V部分，称为色度值或颜色区分值。由以下公式计算： `U = B - Y' V = R - Y'`
> YUV种类：一般我们用4个像素宽，2个像素高的区域举例。主流的采样方式有三种：
> YUV4:4:4(第一行有4组UV。第二行有另外的4组UV。这也叫做“全采样”。)需要占用的内存：w * h * 3
> YUV4:2:2(第一行有2组UV。第二行有另外2组UV。)需要占用的内存：w * h * 2
> YUV4:2:0(第一行有2组UV。第二行没有自己的UV) 占用内存 `y=w*h u=0.25wh v=0.25 yuv相加等于1.5wh`

3. H264编码原理

- 帧内编码:把一帧图像划分成若干宏块,宏块只保存了最上面和最左边的像素，中间的数据根据算法预测到的方向填充
- 帧间编码:I帧、B帧、P帧。与I帧相似度达到95%就编码成B帧，相似度70%就编码成P帧。(该说法只出现在涂程老师的课程里面，google没查到)视频第一帧肯定是I帧第二帧肯定是P帧
- GOP图像序列：可以理解成一组图片，图片的物体都是相似的。两个I帧之间是一个GOP，在一个GOP中只有一个I帧
  ![H261编解码码原理框架图](h264frame.png)
- 编码流程:一个视频第一帧肯定编码成I帧，第二帧如果与第一帧相似程度大于95%就编码成B帧，B帧先放在缓冲器中保存不会直接输出进H264码流。
  接下来的帧如果相似程度大于70%小于95%就会编码成P帧直接输出到H264码流中，P帧主要保存的是宏块和运动矢量。保存在缓冲器中的B帧会根据P帧的运动矢量计算出运动矢量的百分比保存在B帧中。
  最后随机(没有按照缓存顺序)输出缓冲器中的B帧到H264码流中，每一帧都是按照播放顺序(时间戳)
  编码的，但是他们的编码顺序却不一样。I帧保存所有宏块信息，P帧保存运动矢量和宏块，B帧就知保存运动矢量。 I帧的编码最简单耗时最短，B帧编码耗时最长。
- 解码流程:第一帧是I帧直接解码后显示，第二帧是P帧解码后刚入缓冲器，之后几帧是B帧，找到I帧与P帧之间时间戳最小的B帧，解码后输出图像，重复这个过程知道B帧都解码完毕。最后再解码缓冲器中的P帧
- 分隔符:pps、sps、以及每一帧(NALU)的开头都以00 00 00 01或者00 00 01开头。如果像素值出现00 00 00 01或者00 00 01为了避免与分隔符冲突这时候就要在连续00 00
  后面插入03 这种做法叫做转义 解码的时候去掉03 如果像素值真的是00 00 03也去掉03. 分隔符后面是帧类型 0X65代表I帧、0X41代表P帧、0X01代表B帧、0X67代表SPS、0X68代表PPS(可以简单的这样表示，实际情况看NAL头章节)
- 帧类型：SPS 基础配置帧显示格式宽高。PPS全量配置帧包括纠错单元、优先级顺序、策略信息、编码登记。编码器只会输出一次SPS和PPS，但是H264文件有数个SPS和PPS，这是因为播放本地文件或者直播的时候，
  有可能不是从头开始这时候没有SPS和PPS将无法播放，这就要把SPS和PPS缓存起来等编码器输出I帧的时候手动插入PPS和SPS到H264文件中  
- H264数据结构：(H265编码原理详解与码流分析-David\音视频第一节\资料(文档)\文档03-切片)
  ![H264详细结构](77.webp)
  1. NAL层:（Network Abstraction Layer,视频数据网络抽象层）NAL头+切片组成。它的作用是H264只要在网络上传输，在传输的过程每个包以太网是1500字节，而H264的帧往往会大于1500字节，所以要进行拆包，将一个帧拆成多个包进行传输，所有的拆包或者组包都是通过NAL层去处理的。
     **起始码0x 00 00 00 01 或者 0x 00 00 01** 作为**分隔符**。 两个 0x 00 00 00 01之间的字节数据 是表示一个NAL Unit
        1.1 NAL头：第一位 禁止位初始值等于0，等于1表示该单元有错误  
                  第二、三位表示优先级，数字越大优先级越高，当解码器忙不过来的时候会有线抛弃优先级0的NALU，B帧的优先级顺序是00，I帧sps和pps优先级顺序是11
                  剩余5位表示帧类型
                  ![帧类型图](72.png)
                  十进制0代表未使用，十进制5代表I帧，十进制7代表sps(序列参数集)，十进制8代表pps(图像参数集)
  2. VCL层:（Video Coding Layer,视频数据编码层） 对视频原始数据进行压缩。EBSP好像等于VCL，文档没有明说涂老师是这样讲的。NALU = NALU Header + EBSP(片) 。
     EBSP相较于RBSP，多了防止竞争的一个字节：0x03。
  3. H264与H265最大区别是宏块大小，H264最大宏块是16X16本来要保存256个像素H264只需要保存31个像素信息，最小宏块4X4本来要保存16个像素信息H264只保存7个像素信息，宏块越大压缩率越高。
     H265最大宏块64X64最小8X8，虽然H265比H265压缩率更大但是算法更复杂，需要性能更强的设备才能流畅播放，实际上是时间换空间
- H265数据结构：(音视频05-H265码流分析.md)


4. MediaCodec(任何视频流能能解码出完整帧技术)  
本例在decode包
```agsl
- createByCodeName/createEncoderByType/createDecoderByType: //（静态工厂构造MediaCodec对象）--Uninitialized状态
- configure：（配置） -- configure状态
- start        （启动）--进入Running状态
- while(1) {
    try{
       - dequeueInputBuffer    （从编解码器获取输入缓冲区buffer）
       - queueInputBuffer      （buffer被生成方client填满之后提交给编解码器）
       - dequeueOutputBuffer   （从编解码器获取输出缓冲区buffer）
       - releaseOutputBuffer   （消费方client消费之后释放给编解器）
    } catch(Error e){
       - error                   （出现异常 进入error状态）
    }
    
}
- stop                          （编解码完成后，释放codec）
- release
```  

![MediaCodec状态图](https://developer.android.google.cn/images/media/mediacodec_async_states.svg)  
5.录屏(record包)  
[官方文档](https://developer.android.google.cn/guide/topics/large-screens/media-projection)  
6.SPS帧分析
